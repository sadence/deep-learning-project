[DEFAULT]
seq_length = 200
batch_size = 100
input_size = 80
hidden_size = 256
num_layers = 2
num_epochs = 20
learning_rate = 0.00146
dropout = 0

[WORD-LSTM]
seq_length = 50
batch_size = 100
input_size = 200
hidden_size = 300
num_layers = 2
num_epochs = 20
learning_rate = 0.001
dropout = 0

[BENGIO]
seq_length = 50
batch_size = 100
input_size = 200
hidden_size = 300
num_layers = 2
num_epochs = 20
learning_rate = 0.001
dropout = 0